* [EEP153] Week 0
  :PROPERTIES:
  :EXPORT_FILE_NAME: week0.ipynb
  :END:
** Learning goals
   1. Open a =jupyter= notebook on =datahub.berkeley.edu=.
   2. Understand simple =python= expressions.
   3. Work with lists & dictionaries.
   4. Work with =pandas.DataFrames=.
   5. Submit indication of completion.

*** Simple Expressions
Python is a general purpose language, extended via /modules/.
One important aspect of python are /expressions/.  Here are some examples:
#+begin_src ipython
# Arithmetic 
1 + 1

# String (Delineated using single- or double-quotes)
"Hello world!"

# To see output, using a "print" statement:
print(1+1)
print("Hello" + "world!")
#+end_src
   
The above provides examples of:
   - Comments :: Text that begins with a "#" character.
   - Function calls :: Something that takes arguments (in parentheses)
                       and returns some output.  Here "print" is a
                       function.
   - Objects :: 1 and "Hello" are examples of objects.
   - Operators :: "+" is an operator.  Notice that it functions
                  differently depending on what it's operating on;
                  that's because its operation depends on the =type=
                  of the objects (/operands/) it's operating on.  

Predict the output of the following two lines:
#+begin_src ipython
print(type(1+1))
print(type("Hello"))
#+end_src

*** Lists
Strings and integers are simple examples of different data types (or
objects).  A very important type that is more complicated are
=lists=.  Here are some examples.  Examine them, and predict the output:
#+begin_src ipython
a = [1,2,3]
b = ["Hello","world"]

c = a + b
print(c)
print(len(c))  # Here len returns the "length" of the list.
#+end_src


Extra optional practice to refresh yourself with list manipulation and slicing.
Examine these first, then predict the output.
#+begin_src ipython
print(c[2]) # Remember how Python counts arrays.
print(c[1:2]) # Why does Python only return one item instead of two?
print(b[0]*4)
print(c[0::2])
print(list(map(lambda x: x*2,a)))
#+end_src

*** Dictionaries

Another very basic kind of compound object are =dicts= (dictionaries;
also called associative arrays or hashes in other languages).  Predict
the output:

#+begin_src ipython :results output
d = {'name': "Barney", 'species': "Dinosaur", 'age': 27, 'color': "Purple"}

print("{name} the {species} is {color}.".format(**d))
#+end_src

*** DataFrames

A much more complicated data structure is provided by a module called
=pandas=; you can find a quick tutorial at
http://pandas.pydata.org/pandas-docs/version/0.23/10min.html.  The
DataFrame object will be very important for us.

The =pandas= module provides a data structure called a =DataFrame=.
These are basically rectangular arrays of data, with names for rows
and columns, rather like a spreadsheet.  In fact, one important thing
one can do with DataFrames is to import data /from/ spreadsheets.
#+begin_src ipython :session
import pandas as pd

# Try looking at https://docs.google.com/spreadsheets/d/1ObK5N_5aVXzVHE7ZXWBg0kQvPS3k1enRwsUjhytwh5A in your browser.
SHEET = "https://docs.google.com/spreadsheets/d/1q1ikP1CXCcLf_Tq6VbhoskOYRvn_nDU5MHStIoVzMgA"

# The following line goes on-line and turns the spreadsheet into a pandas DataFrame:
df = pd.read_csv(SHEET + "/export?format=csv")

# This line will show us only the first five rows of data. Try removing .head() to see the full list of items.
# Guess what happens if you replace .head() with .tail(). Try it out!
df.head()
#+end_src

If this worked (!) you should be able to see some data from a recent
shopping trip of mine.  What are the different variables available in
the DataFrame =df=?  They correspond to the /columns/ of the spreadsheet.

#+begin_src ipython :session
df.columns
#+end_src

Now, what else can we do?  Let's figure out how much my total grocery
bill was:

#+begin_src ipython :session
df['Price'].sum()
#+end_src

Let's say I'm on a budget. Naturally, we'd want to identify the item(s)
I'm spending the most on. We can sort the values to investigate further.

#+begin_src ipython :session
# Note that we're indicating we want to sort by the 'Price' column and specify that it should be in descending order.
df.sort_values(by='Price', ascending=False).head()
#+end_src

Everything here looks straightforward, but let's take a closer look at
Red Endive and calculate the price per pound to make comparison easier.

#+begin_src ipython :session
# This line selects the 7th item in the dataframe (note the index number is 6 because we start counting at 0 when we use Python)
# and selects the 'Price' value for this particular item. It divides it by 'Quantity' to get the price per pound.
df.iloc[6]['Price']/df.iloc[6]['Quantity']
#+end_src

You'll find throughout the semester that unit price is a pretty useful statistic
to calculate. Let's do it for all the items on this grocery list. Thankfully we
don't have to do this one by one.

#+begin_src ipython :session
# This line creates a new column in our dataframe named 'Unit Price' and populates each row with the respective price value 
# divided by the quantity value.
df['Unit Price'] = df['Price']/df['Quantity']
df.head()
#+end_src

Almost there! Let's pare down our dataframe to look more friendly to the eye. We
don't want to see the following columns: Date, Location, NDB. Also, we only want to see
the first five items of the dataframe. 

In the previous blocks, we used .iloc which stands for index (or integer) location. We used integers to specify which
columns we wanted. In this section, we'll use .loc which allows us to use column labels. For extra practice, try to
achieve the same result but by using .iloc instead.

#+begin_src ipython :session

# Note that in both the .iloc and .loc syntax, the first set of parameters refer to rows and the second set refer to columns.
df.loc[0:5, ['Food', 'Quantity', 'Units', 'Price', 'Unit Price']]
#+end_src

Here's one last exercise that might be useful. Often times you will only want to view data
that fits a certain criterion. In this case, let's only look at items where the unit price
is less than 1.

#+begin_src ipython :session
# This line will return all rows in the dataframe where the Unit Price is < 1. Using what we've covered prior,
# modify the view of this dataframe to only include Food and Unit Price.
df[df['Unit Price'] < 1]
#+end_src

Extra things to refresh that may be helpful for Project 1: basic visualizations, datatypes, index, joins.

*** Final words
Throughout this class, you will be exposed to a variety of Python modules and tools and the data that you work with
may or may not be cleaned. In any case, learning how to find and use online documentation/resources is a
valuable skill that will benefit you greatly in this course and beyond. Be sure to utilize our course discussion
for any questions you might have - there's a good chance a peer may have a similar question or have the answer.
As the semester goes on, course staff will update the "Useful Links/Resources" post with any outside Python resources 
that may be helpful for the whole class.


* Authentication & Working with Google Sheets from Python
  :PROPERTIES:
  :EXPORT_FILE_NAME: ../Materials/Tools/gspread_authentication.ipynb
  :END:
  Some programming tools you'll learn from this notebook:
   1. Decrypting Google Drive API credentials using =GPG=
   2. Using =gspread= to read Google Spreadsheet data
   3. Using =gspread= to write Google Spreadsheet data

** Credential decryption
   Protecting access to sensitive information is paramount to any
   organization's security. In this class, the information we will be
   sharing with you is not highly sensitive. However, learning how to
   work with decryption is a handy skill that you might find useful
   after this course.

   In this cell, we will run a shell command that leverages the GPG
   module to decrypt the file =students-9093fa174318.json.gpg= located
   in your server. Notice how we do this with the =!= symbol before
   typing in the rest of the code. Be sure to insert the passphrase
   provided to you.

#+begin_src ipython
# Replace PASSPHRASE in the next comment with the secret we've shared with you  
# via piazza.

!gpg -d --batch --passphrase "PASSPHRASE" ../students-9093fa174318.json.gpg > ../students-9093fa174318.json
!ls -l  ../students-9093fa174318.json
#+end_src

   Take a look in your jupyter server directory (or its parent) and
   you should see a new file named
   =students-9093fa174318.json=. Protect this file carefully, as
   anyone who has this can now access the spreadsheets we'll introduce
   you to in this course.

** Reading Google Spreadsheet data

   In this section, we'll read data from Google Spreadsheet using a
   module called =GSpread=. You're not expected to be fully understand
   all the functions of this module, though knowing how to read
   spreadsheet data with basic =GSpread= functions may be helpful for
   this project and beyond.

*** Initial Set-up
   In this first cell, we provide the initial setup that will allow
   you to access this spreadsheet:
   https://docs.google.com/spreadsheets/d/1xoAe1BlXb7m3ZSB-Tm5XkkVn0W6xkS3y5zl48TqVSsk/.

#+begin_src ipython
# !pip install gspread
import gspread
from oauth2client.service_account import ServiceAccountCredentials

scope = ['https://spreadsheets.google.com/feeds',
         'https://www.googleapis.com/auth/drive']
#+end_src

   Now, we'll input the credentials you decrypted in the previous
   section and specify the spreadsheet we want to open in Python.

#+begin_src ipython
# This should be the default .json file pathway, but feel free to change
# json_file if your pathway if different.

json_file = '../students-9093fa174318.json'
spreadsheet = '1xoAe1BlXb7m3ZSB-Tm5XkkVn0W6xkS3y5zl48TqVSsk'
credentials = ServiceAccountCredentials.from_json_keyfile_name(json_file, scope)
gc = gspread.authorize(credentials)

sh = gc.open_by_key(spreadsheet)

#+end_src

*** Accessing Values
   Our spreadsheet is now open by an instance of =gspread=, and you
   can access it in the variable =sh=. To explore this data, you
   might find more value exploring it in your browser. A couple
   technicalities to be aware of:
      -  A =spreadsheet= is the overall container that holds multiple
         worksheets.
      -  A =worksheet= is a single tab in a spreadsheet.

#+begin_src ipython
# This cell provides you with a list of all worksheets contained in the
# spreadsheet. If you already know which spreadsheet you want to access,
# you can ignore this cell.

sh.worksheets()
#+end_src

#+begin_src ipython
# This cell allows you to access a particular spreadsheet within the worksheet.
# Even if your spreadsheet has only worksheet, you still must specify the
# worksheet you wish to read data from.

wks = sh.worksheet("Expenditures")

# Alternatively, you can use the following code snippets to achieve the same result.
# wks = sh.get_worksheet(0)
# wks = sh.sheet1
#+end_src

   Now that the worksheet is selected, we can begin reading data.

#+begin_src ipython
row_vals = wks.row_values(1) # All values in row 1, stored in an array. 
col_vals = wks.col_values(1) # All values in column 1, stored in an array.

# This line gives you the first five values of row_vals and col_vals. Feel free
# to change around the indices to see more data, or skip to the next cell for a
# more holistic view.

row_vals[:5], col_vals[:5]
#+end_src

   A more standard usage of =gspread= is reading this data into a
   =pandas= dataframe. This next cell does exactly that. Feel free to
   use the exercises from Week 0 to refresh =pandas= specific
   functions to manipulate and explore the dataframe. 

#+begin_src ipython
import pandas as pd

data = wks.get_all_values()
headers = data[0]
data_df = pd.DataFrame(data[1:],columns=headers)
data_df.head() 
#+end_src

   This is just a basic introduction to reading data from Google
   Spreadsheets using =GSpread=. For more information and
   documentation, visit https://gspread.readthedocs.io/en/latest/index.html.

** Writing Google Spreadsheet data

   In this section, we'll write data to a new Google
   Spreadsheet located here:
   https://docs.google.com/spreadsheets/d/1dhJUonTO5AcKgvLX06hjhyQOA9BtcUmVdKf-0eNIKzw/edit?usp=sharing.
   You'll notice that you can only view the spreadsheet, not
   edit. However, using the credentials provided to you previously,
   you'll be able to submit an indication of completion by writing
   your name in two places: =Master Sheet= and the tab corresponding
   to your team assignment. 

#+begin_src ipython
# This cell changes the spreadsheet and opens the first worksheet.
spreadsheet = '1b9sZWRcOR2Bupg_9WLywHPY2ZbPwztrP67XTl24Op5w'
sh = gc.open_by_key(spreadsheet)
wks = sh.get_worksheet(0)
#+end_src

   Now that we're in the new spreadsheet and selected the first
   worksheet, open up the link above and identify the cell you want to
   put your name in. (Example: B3)

#+begin_src ipython
# Make sure to update 'cell' with the cell you would like to update (e.g., "H2"),
# and 'YOUR NAME' with your name!
wks.update_acell('CELL', 'YOUR NAME')

# Alternatively, you can update the cell using the following syntax:
#wks.update_cell(ROW_NUM, COL_NUM, 'YOUR NAME')
#+end_src

   If you look back at the spreadsheet, you should see your name in
   the cell you selected. Let's do it one more time in the tab with
   your team name. Try this one by yourself!

#+begin_src ipython
# HINT: Make sure to change the spreadsheet you've selected, look at the previous
# section for guidance on how to do this if you forgot.
#+end_src

   This concludes this notebook: reading and writing data to/from
   Google Spreadsheets programmatically using Python. One area not
   covered is writing entire =pandas= Dataframes to a spreadsheet. For
   larger datasets, its recommended to use the =gspread-dataframe=
   module instead of looping through and updating cells
   one-by-one. Check out this module here: https://pythonhosted.org/gspread-dataframe/.


* [EEP153] Week 2
  :PROPERTIES:
  :EXPORT_FILE_NAME: week2.ipynb
  :END:
  Some programming learning goals for week 2:
   1. Writing =pandas= dataframes to a Google Spreadsheet using
      =gpsread-dataframe=
   2. Docstrings, documentation, comments
   2. Inspecting objects
   3. Interpreting exceptions
   4. Reading tracebacks

** Writing a =pandas.DataFrame= to Google Spreadsheet
   In last week's exercise, we explored the basic functionality of
   =gspread= to read and write spreadsheet data using Python. Writing
   cell data one by one, however, is not the most efficient way to
   write data especially if you have a dataframe with thousands of
   observations. Here, we'll extend our knowledge from last week to
   write data directly from a dataframe into a spreadsheet.

   In this cell, we setup our notebook to use the packages we'll need
   for the demo. You may need to uncomment the first two lines
   depending on if you encounter a =ModuleNotFoundError= or
   =NameError=.

#+begin_src ipython
#!pip install wbdata
#!pip install gspread-pandas
import wbdata as wb
import pandas as pd
import gspread_pandas as gsp 
#+end_src

   Remember how we decrypted credential keys last week? We're going to
   do the same thing here using the team-specific keys shared with
   your group on Piazza last week. Look in the
   =EEP153_Materials/Project 1= respository on =datahub= to get the
   file name of the =.json.gpg= credentials file that corresponds to
   your team. Then look at Piazza for your team-specific passphrase.

#+begin_src ipython
# Replace PASSPHRASE with the secret phrase we shared with your team on
# Piazza. Replace FILENAME with the filename (without the extension)
# of the encrypted credential file.

!gpg -d --batch --passphrase "PASSPHRASE" ../EEP153_Materials/Project1/FILENAME.json.gpg > ./FILENAME.json
#+end_src

   Now, we have the credentials that will allow you to access your
   team-specific Google Drive. It is with these credential that you
   will create and share spreadsheet data with your team. In this next
   cell, we set up our =gspread_pandas= client with our credentials.

#+begin_src ipython
# Replace FILENAME with the filename of your decrypted .json file.

user_config = gsp.conf.get_config(conf_dir='./',file_name='FILENAME')
user_creds = gsp.conf.get_creds(config=user_config)
client = gsp.Client(creds=user_creds)
#+end_src

   Now we're in your team drive, except you can't really see
   it. We can explore what we're working with without your
   browser. =gspread-pandas= provides a series of functions that will
   allow us to do exactly this. 

#+begin_src ipython
# Returns all spreadsheet files you have access to.
client.list_spreadsheet_files()

# Returns all available folders or directories you can access.
#client.directories

# Returns information for the root directory.
#client.root

# Returns the email you can share spreadsheets to.
#client.email
#+end_src

   Presumably, your Drive is empty at the moment. Before we start
   creating sheets into the main directory, let's create a folder to
   provide some structure.

#+begin_src ipython
# You can replace "W2 Example" with whatever file name you like.
client.create_folder('W2 Example')
#+end_src

   You'll notice that a dictionary was returned. It confirms the
   pathway of the folder and a unique ID you can refer to at any
   time. If you were to try copy and pasting this ID and access this
   folder on your browser, you'll find that you won't have access!
   We'll cover permissions later.

   Now, we'll create a spreadsheet and move it to the new
   folder. This spreadsheet will serve as our container for our
   dataframe we'll create.

#+begin_src ipython
# If you changed your folder path or name in the previous cell, make sure to 
# change it here too.
spread = gsp.Spread('My wbdata', create_spread=True,creds=user_creds)
spread.move('W2 Example')

# To confirm we've successfully moved it over, this next line should show you
# that 'My wbdata' is in the 'W2 Example' folder.
client.find_spreadsheet_files_in_folders('W2 Example')
#+end_src

   Let's create a =Pandas= dataframe to populate =My
   wbdata=. Hopefully this next cell looks a little familiar.

#+begin_src ipython
variable_labels = {"SP.POP.TOTL":"Total Population",
                  "SP.POP.TOTL.FE.IN":"Total Female Population",
                  "SP.POP.TOTL.MA.IN":"Total Male Population"}
chn = wb.get_dataframe(variable_labels, country="CHN")
chn = chn.iloc[1:,]
chn.head()
#+end_src

   Moving it to our spreadsheet is a one-liner. Run the next line and
   you're done!

#+begin_src ipython
spread.df_to_sheet(chn)
#+end_src

   If you don't believe it, run the next line to give yourself access
   to see it in your browser. Then, check your email.

#+begin_src ipython
spread.add_permission('YOUR_EMAIL|reader')
#+end_src

   You can now easily take this Google Spreadsheet data and put it
   into a =Pandas= dataframe for manipulation in python in a similar
   fashion.

#+begin_src ipython
chn2 = spread.sheet_to_df()
chn2.head()
#+end_src

   This was a high-level introduction to =gspread-pandas=. For more
   information and functions that is provided in this package, check
   out the documentation here:
   https://gspread-pandas.readthedocs.io/en/latest/getting_started.html.

** Docstrings, documentation, and comments
   Often times, you will encounter code blocks that leverage packages
   and functions you have never seen before. In your attempt to
   understand what the code is doing, you might find yourself going back
   and forth between documentation pages and your Jupyter notebook.

   This section aims to share best practices when working through
   novel code blocks. You will be able to use and create docstrings,
   breakdown documentation, and strategically leave comments to make
   your code more readable.

#+begin_src ipython
# Uncomment the next two lines if you encounter an error. We will talk about
# this later in the exercise. 

#!pip install geopandas
#!pip install descartes
import geopandas
import matplotlib.pyplot as plt

def f(a, b, c):
    gdf = geopandas.GeoDataFrame(a, geometry=geopandas.points_from_xy(a['u'], a['v']))
    world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))
    ax = world[world.name == b].plot(color='white', edgecolor='gray')
    gdf.plot(ax=ax, color='red',marker='o')

    for i, j, k in zip(df['u'], df['v'], df['t']):
        ax.annotate(k, xy=(i,j),xytext=(-16,8), textcoords="offset pixels")

    plt.title(c)
    plt.xlabel('x')
    plt.ylabel('y')
    plt.show()
#+end_src

   In the cell above, we are introduced to a new function =f= that calls a
   series of functions from =geopandas=. The author didn't do a great
   job at picking descriptive labels for the parameters used in this
   function. Normally, we could decipher enough to experiment with the
   function, but here we don't have much to go off of. Let's pick
   apart the function line by line to figure out what exactly is going on.

#+begin_src ipython
# Cick anywhere within the string "GeoDataFrame" and press SHIFT + TAB
# Press the + in the upper right corner to expand the docstring

gdf = geopandas.GeoDataFrame(a, geometry=geopandas.points_from_xy(a['u'], a['v']))

# There's a nested function in this line too, so let's take a look.
# Another way of looking at the docstring is illustrated in the commented line below

geopandas.points_from_xy(a['u'], a['v'])
#geopandas.points_from_xy?
#+end_src

   We can infer that =a= is probably some form of Pandas dataframe. We
   know this because =GeoDataFrame='s docstring tells us that the
   object is a =pandas.DataFrame= that has a column with
   geometry. This is a constructor and uses a =pandas.DataFrame= to
   build this =GeoDataFrame= object. If you didn't catch that, we are
   also given a hint in the =.points_from_xy= function and its
   docstring which gives an example that looks suspiciously similar to
   this implementation. 

   =u= looks to be \(x\)-coordinates and =v= looks like it could be
   \(y\)-coordinates. We might reasonably guess that these may be
   coordinates for a map (perhaps longitude and latitude), given that
   geopandas is a mapping tool.

#+begin_src ipython
# Explore the docstring for .read_file and .get_path
world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))

#geopandas.datasets.available
#type(world)
#world.head()
#+end_src

   We see in the next line ~world[world.name==b]~ which is a way of
   filtering the =world= dataframe for rows in which the value in
   column =name= is equal to some parameter =b=. Looking at
   =world.head()=, we can see that the =name= column is filled with what
   looks like countries. It might be reasonable to infer that in the
   next line (referenced in the code block below), the function is
   looking to plot one particular country.

#+begin_src ipython
# Try changing 'b' to 'United Kingdom'
ax = world[world.name == b].plot(color='white', edgecolor='gray')
#+end_src

   The last line we'll run through in depth is the next one. Similar
   to before, read the docstring and guess what will happen. We can't
   run this cell because we haven't defined gdf properly.

#+begin_src ipython
gdf.plot(ax=ax, color='red',marker='o')
#+end_src

   Here's the rest of the function for your reference. The remainder
   of the lines don't rely on =geopandas=. Rather, they are native to
   =python= and =matplotlib= (the latter imported as =plt=, see first
   code block above). Check out the docstrings using SHIFT + TAB or ?.

#+begin_src ipython
for i, j, k in zip(df['u'], df['v'], df['t']):
    ax.annotate(k, xy=(i,j),xytext=(-16,8), textcoords="offset pixels")

plt.title(c)
plt.xlabel('x')
plt.ylabel('y')
plt.show()
#+end_src

   Our final observations: =c= is a string that is being passed to a
   function =title= in the package (aliased as) =plt=.  We can assume
   then that =c= is a title of a plot that will inevitably be returned
   as shown by the last line =plt.show()=. We also see =df= has a
   column =t= that corresponds to some =k=. Upon closer inspection of
   =.annotate=, this is a function that takes strings and plots it on
   specific points on a map. We can guess that =t= is filled with text
   labels of some sort.

   Let's recap what we think is going on here. This is a function that
   takes three arguments: dataframe =(a)=, country =(b)=, title
   =(c)=. This dataframe =a= should have the following columns: =t=
   (labels), =u= (longitudes or x-coordinates), =v= (latitudes or
   y-coordinates). We also know that =b= is a country and =c= is the
   plot title. 

#+begin_src ipython
df = pd.DataFrame(
    {'t': ['London','Edinburgh','Cardiff','Belfast'],
     'u': [-0.1278,-3.1883,-3.1791,-5.9301],
     'v': [51.5074,55.9533,51.4816,54.5973]})

f(df,'United Kingdom','Capitals of the countries within the United Kingdom')
#+end_src

   Now that we've successfully deciphered this function. Let's do
   everyone that comes after you a big favor and update the
   docstring. Run the next cell to redefine the function with the new
   docstring.
   
#+begin_src ipython
def f(a, b, c):
    """
    This function takes three arguments: dataframe, country, title and returns a plot.
    
    Parameters
    ----------
    a : pandas df
        Only three columns labeled 't', 'u', 'v'
        t = labels (str), u = longitudes (float), v = latitudes (float)
    
    b : str
        Must be an exact match. e.g. United States of America vs. USA.
    
    c : str
        Title of the plot.
        
    """
    
    gdf = geopandas.GeoDataFrame(a, geometry=geopandas.points_from_xy(a['u'], a['v']))
    world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))
    ax = world[world.name == b].plot(color='white', edgecolor='gray')
    gdf.plot(ax=ax, color='red',marker='o')

    for i, j, k in zip(df['u'], df['v'], df['t']):
        ax.annotate(k, xy=(i,j),xytext=(-16,8), textcoords="offset pixels")

    plt.title(c)
    plt.xlabel('x')
    plt.ylabel('y')
    plt.show()
#+end_src

   The next cell gives you a new map, this time of Canada's provincial
   capitals. Try checking out the docstring this time with SHIFT + TAB
   or ?. 

#+begin_src ipython
df = pd.DataFrame(
    {'t': ['Victoria','Whitehorse','Edmonton','Yellowknife','Regina','Winnipeg','Iqaluit','Toronto','Quebec','Fredericton','Halifax','Charlottetown','St. Johns','Ottawa'],
     'u': [-123,-135,-113,-114,-105,-97,-69,-79,-71,-67,-64,-56,-53,-76],
     'v': [48,61,54,62,50,50,64,44,47,46,45,53,48,45]})

f(df, 'Canada', 'Canada\'s provincial capitals')
#f?
#+end_src

   In this section, we learned how to leverage docstrings to our
   advantage when deciphering code and we now know how to make our own
   docstrings to help people in the future decipher code we create. 

   Docstrings often align heavily with documentation you can find
   online. However, navigating the official package documentation may
   provide you with more code examples or even shed some light on
   functionalities you may not be aware of. Check out the links below
   and see what you can find!
      - http://geopandas.org/index.html
      - https://matplotlib.org/api/index.html

   Periodically in the code blocks above, we used =#= to denote
   comments in our code. You can also use these in lieu of docstrings
   to provide explanation or directions to people who are viewing your
   code in the future. In the exercises below, we'll ask you to add
   comments to the function we defined previously.

** Debugging
*** Inspecting objects
    A common issue we run into is making false assumptions about an
    object and writing code based off this notion of what we believe
    the object to be. A simple example is item type (str, float, int,
    etc.)

#+begin_src ipython
# Let's go back to the dataframe we created in the first section.
chn.head()
#+end_src

#+begin_src ipython
# Now try to pull the row from 2018, and we'll encounter a TypeError.
chn.loc[2018]
#+end_src

#+begin_src ipython
# Sure enough, upon inspection, we discover it's an index of strings.
type(chn.index.values[0])
#+end_src

#+begin_src ipython
# Let's use a roundabout method to get a new array of dates in integers.
new_index = wb.get_dataframe({"SP.POP.TOTL":"Total Population"},country="CHN").index.astype(int).values
new_index
#+end_src

#+begin_src ipython
# However, when we set the new index, we get a ValueError.
chn.index = new_index

# Upon inspection, we confirm the different lengths and we can make a quick fix.
#len(chn.index), len(new_index)
#+end_src

   These are simple cases that underscore the importance of
   understanding what your objects consist of and what they look like
   before you manipulate them. You can save yourself precious
   debugging time through a brief inspection of your objects.
   
   Helpful inspection functions:
      - =type()=
      - =df.columns=
      - =df.shape=

*** Interpreting exceptions
    Though we've seen  =ValueError= and =TypeError=, there are
    numerous other errors and exceptions that you may come across over
    the course of this class and beyond. These error messages may
    provide valuable information to help guide your troubleshooting.

#+begin_src ipython
# Key Error
chn.loc[2019]
#chn['total population']
#+end_src

#+begin_src ipython
# Index Error
chn.iloc[:,3]
#wb.get_dataframe({"SP.POP.80UP":"80+ Population"},country="CHN")
#+end_src

#+begin_src ipython
# Name Error
np.sum(chn['Total Population'])
#wbdata.get_dataframe({"SP.POP.80UP":"80+ Population"},country="CHN")
#+end_src

#+begin_src ipython
# Attribute Error
chn.name
#chn['Total Population'].columns
#+end_src

#+begin_src ipython
# Syntax Error disguised as something else
print("The total population of China in", chn.index.values[0], "is", int(chn.loc[chn.index.values[0], "Total Population"], "."))
#+end_src

*** Reading tracebacks
    The last valuable skill to come out of this exercise is the
    ability to read tracebacks. When you encounter an error, Python
    will return a log of code that Python attempted to run, often
    tracing back several functions that will allow you to pinpoint
    exactly what went wrong.

    In this next cell, we introduce a function =twentyfirst_cent_pop=
    which returns a Pandas dataframe of total population for a
    particular country and creates a simple line graph if you specify
    =graph=True=.

#+begin_src ipython
def twentyfirst_cent_pop(cntry_code, graph=False):
    variable_labels = {"SP.POP.TOTL":"Total Population"}
    
    df = wb.get_dataframe(variable_labels, country=cntry_code)

    df.index = df.index.astype(int).values
    df = df.loc[2018:2000,]
    
    if graph:
        lines = df.plot.line()
        plt.title('Total population of ' + cntry_code + ' over the 21st c.')
        plt.xlabel('Year')
        plt.ylabel('Population')
    return df

#Try looking at Ukraine, Russia, Belarus, Hungary, Italy or Greece
twentyfirst_cent_pop("JPN",graph=True).head()
#+end_src

#+begin_src ipython
# What happens if we purposefully break this function?
twentyfirst_cent_pop("").head()
#+end_src

   When we pass an empty string, our function raises a TypeError and
   mentions something about a MultiIndex. Using the traceback, we see
   that line 5 is having an issue. We know it successfully gets
   through the =wb.get_dataframe= statement, and we can verify that by adding a
   print statement.

   Take a look at what =df= is when we pass in an empty string into
   the function. 

#+begin_src ipython
# Here we can see what happens when we pass in an empty string. A similar
# behavior is exhibited when we run our function: a MultiIndex with all 
# countries and years.

#wb.search_countries("",display=True)
wb.get_dataframe({"SP.POP.TOTL":"Total Population"}, country=" ")
#+end_src

   Now that we've visualized the problem (MultiIndex instead of a
   single-level index), we can develop a fix. We know that we want to
   detect a blank input before it gets to the first try
   statement. That way, we can raise a more helpful error message
   compared to what we saw earlier. Try copy + pasting this into the
   function cell right before =try=.

#+begin_src ipython
    if len(cntry_code.strip())==0:
        raise ValueError('Must input a value!')
#+end_src

   It will still raise an error, but now there's a helpful message to
   the user who may not know how to debug the function themselves. Our
   error message directs users to input a value, and hopefully then,
   they can get on their way.
   
** Test Your Understanding
   1. Using =pandas= and =gspread-dataframe=, each team should submit
      their attendance by sharing a spreadsheet with the following
      columns: First Name, Last Name, E-mail. Share your spreadsheet
      with =cardinali@berkeley.edu= and =ligon@berkeley.edu=.

   2. Write a docstring for =twentyfirst_cent_pop=. Follow the
      template from function =f= in Section 2.

   3. See below for debugging exercises

#+begin_src ipython
# Fix the NameError
pd.DataFrame(data={'Growth Rate':np.diff(np.log(chn['Total Population'][::-1]))}).plot.line();
plt.title('Population Growth Rate of China from 1960-present');

# Fix the TypeError such that this line works
chn.loc[2018:2009,]
#+end_src


* [EEP153] 
  :PROPERTIES:
  :EXPORT_FILE_NAME: week4.ipynb
  :END:
  Some programming learning goals for week 3:
  1. List comprehensions
  2. Some string operations
  3. Understand simple recursions.
  4. Use lambda expressions (anonymous functions)
  5. Root-finding for equations of one variable
** List comprehensions
   You're already familiar with =for= loops like the following, which 
   computes the squares of a list of numbers:
   #+begin_src ipython
L = []
for i in [0,1,2]:
    L.append(i**2)

print(L)
   #+end_src
   This is pretty clear, but not very elegant.  Consider instead the
   following /list comprehension/:
   #+begin_src ipython
L = [i**2 for i in [0,1,2]]

print(L)
   #+end_src

** Simple recursions
   A recursion, or a recursive function, is a function that may call
   itself when evaluated.  Here's a very simple recursion:
   #+begin_src ipython
def foo(n):
    """Sum of postive integers up to n."""
    if n==0:
        return 0
    else:
        return n + foo(n-1)

foo(43)
   #+end_src
 
   The fact that evaluating =foo(n)= involves calling =foo(n-1)= is
   what makes this a recursion.

   If you give this even a little thought you'll be able to think of
   more efficient ways to do this; it's the demonstration of the
   simple pattern we're after.

   Here's another, which operates on lists of numbers:
   #+begin_src ipython
def bar(x):
    """What does this function do, and how does it do it?"""
    if x==[]: return 0 
    
    try:
        return bar(x[0]) + bar(x[1:])
    except TypeError: # x not a list?
        return x   
   #+end_src

   #+begin_src ipython
# Try calling bar after predicting its output:
bar([21,14,3,4])
   #+end_src

   The function =bar= also could be implemented much more efficiently!

   Finally, here's a function which /is/ useful (in fact, we'll use it
   below).  This takes a list (or tuple) which may consist of lists,
   and "flattens" it so that none of the elements are lists.  For
   example, =flatten([1,[2,3]]) -> [1,2,3]=.
   #+begin_src ipython
def flatten(a):
     if not isinstance(a,(tuple,list)): return [a]
     if len(a)==0: return []
     return flatten(a[0])+flatten(a[1:])

print(flatten([1,[2,3]]))
   #+end_src

** Some string operations
   We're interested here in a couple of simple ways to map strings
   into lists and lists into strings.  One common problem: you may
   have a string like "1,2,3,fiver".  
   #+begin_src ipython
s = "1,2,3,fiver"

# s can be treated like a list.  What is s[1]?
s[1]
   #+end_src

   So strings can be treated as lists of characters, at least for some
   purposes.  But the string above suggests a /different/ list, one
   with four elements.  To obtain this, consider
   #+begin_src ipython
t = s.split(',')
print(t)
   #+end_src

   We can also go the other way; given a list, we can turn it into a
   string, with the different elements separated by a string of our choice:
   #+begin_src ipython
" and ".join(t)
   #+end_src

   So how about using recursions and these string operations to
   actually do something useful?  Let's write a function that can take
   a string representing ranges of numbers, like "1,2-4,3-5,0-3" and
   return list of the numbers that appear (perhaps implicitly) in the
   string.
   #+begin_src ipython
def range_parser(s,unique=False):
    """
    Parse a string of numbers including ranges indicated by '-',
    and return a sorted list of all such numbers.

    If the optional flag unique is True, then return a list in
    which no numbers are repeated.

    Ethan Ligon                               February 2019
    """
    if unique:
        return sorted(list(set(range_parser(s,unique=False))))
    
    try: # Maybe we just have a single number, like '3'?
        return [int(s)]
    except ValueError:
        if ',' in s: # Or maybe we have a string with commas?
            return sorted(flatten([range_parser(x) for x in s.split(',')]))
        elif '-' in s:
            a,b = [range_parser(x)[0] for x in s.split('-')]
            return list(range(a,b))
        
print(range_parser("1,2-4,3-5,0-3",unique=True))
   #+end_src



** lambda expressions (anonymous functions)
   This is incredibly obvious to some people, but for others it takes
   some work to wrap their heads around.  But hopefully this will make
   this all obvious.  *Predict the output*:
   #+begin_src ipython
# Consider the two following functions

def f(x):
    return 1/x - 1

g = lambda x: 1/x -1

print(f(3) - g(3))
   #+end_src
   It may help to think of objects like =g= or =f= not as functions,
   but instead as names of or references to functions.

** Root-finding
   If we have a function (referred to by) =f= that takes a single
   scalar argument and returns a real number, then we may often be
   interesting in equations such as 
   \[
   f(x) = 0;
   \]
   the problem then is to find a value of $x$ that satisfies the
   equation.

   The first thing we might worry about is that no such solution
   exists.  Sometimes this is something we can check in advance.  For
   example, if can find a value $a$ such that =f(a)= is positive and a
   value $b$ such that =f(b)= is negative, the continuity of the
   function (named) =f= gives us a mathematical guarantee that a zero
   of the function exists.  

   However, even for continuous unbounded functions there is no
   algorithm that's guaranteed to locate a zero for /any/ such
   function.  Some algorithms work better than others, and some are
   designed to work with particular classes of functions.

   One quite robust (but often slow) method is a method called
   /bisection/.  This uses the idea above: start by finding values
   $(a,b)$  such that $f(a)>0>f(b)$.  Then if $f$ is continuous we
   know there must be a zero on the real interval $[a,b]$.  Divide
   this interval in half, and evaluate $f((a+b)/2)$.  If this is
   positive, then we know there must be a zero on the interval
   $[(a+b)/2,b]$; if negative, that there must be a zero on
   $[a,(a+b)/2]$.  Take this new smaller interval, and repeat.  Keep
   going until the evaluation of the function (named) =f= is close to
   zero.

   The python package =scipy= includes a module =optimize= which
   includes a variety of different routines to both find optima (i.e.,
   maxima and minima) as well as closely related routines to find the
   zeros of functions.  Here's an example of the use of the bisection
   algorithm:
   #+begin_src ipython
from scipy.optimize import bisect

x = bisect(lambda x: 1/x-1,.001,100)
print(x)
   #+end_src

   A much faster method is called the /secant/ method, and was known
   to the ancient Babylonians and Egyptians at least as early as 1800 BCE.
   The discovery of the calculus in the 18th century allowed Newton to
   improve on the secant method, but his approach requires not only
   the function be continuous, but also continuously differentiable;
   further, one must supply a function describing the derivatives.
   Both the secant method and Newton's method are available from
   =scipy.optimize=.
   #+begin_src ipython
from scipy.optimize import newton

# If we supply just a function and a starting place we
# get the secant method:
   
x = newton(f,1.01)  # Solution is one; if we start close we should find it!
print(x)  

x = newton(f,2)  # Not always robust!
print(x)
   #+end_src

   Now try Newton's method:
   #+begin_src ipython
df = lambda x: -x**(-2) # Derivative of function named f

# Supply derivative function, get Newton's method
x = newton(f,2,df)   # Still not necessarily robust!
print(x)
   #+end_src

   Newton's method works better with polynomials:
   #+begin_src ipython 
f = lambda x: -1 + x - 3*x**2 + 4*x**3

df = lambda x: 1 - 6*x +12*x**2

x = newton(f,10,df)
print(x)
   #+end_src

   
* [EEP153] Week 6
   :PROPERTIES:
   :CUSTOM_ID: eep-153-week-6
   :EXPORT_FILE_NAME: week6.ipynb
   :END:

Some programming learning goals for week 6:

1. String formatting and operations
2. Exceptions
3. More useful pandas practice

** 1. String Formatting Exercise 
   :PROPERTIES:
   :CUSTOM_ID: string-formatting-exercise
   :END:

Use https://pyformat.info as a reference. 

#+BEGIN_SRC ipython
myCat = { "Name":"Beatrice", "Age":7,"Nickname":"Queen B"}

# Exercise: Print out the string "My cat's name is Beatrice, but we usually call her Queen B."
#+END_SRC

** 2. Errors 
   :PROPERTIES:
   :CUSTOM_ID: errors
   :END:

There are two types of errors: syntax errors, and exceptions.

Syntax errors occur when the parser detects an incorrect statement.
Exception errors occur when whenever syntactically correct Python code
results in an error. Python comes with various built-in exceptions as
well as the possibility to create self-defined exceptions.

*** Raising an exception
    :PROPERTIES:
    :CUSTOM_ID: raising-an-exception
    :END:

We can use raise to throw an exception if a condition occurs. For
example: run the code below, then un-comment the second line of code and
run again.

#+BEGIN_SRC ipython
x = '50'
#if isinstance(x,(str)): raise Exception('x should not be formatted as a string')
print(x)
#+END_SRC

*** Try, Except, Finally
    :PROPERTIES:
    :CUSTOM_ID: try-except-finally
    :END:

A try block lets you test a block of code for errors, an except block
lets you handle the error, and a finally block lets you execute code,
regardless of the result of the try- and except blocks. 

 You can have multiple except blocks, which allow you to
respond in a particular way to different types of errors.

 In the example below, try running the code as is, then
after un-commenting the first line. See you if you can fix the error.

#+BEGIN_SRC ipython
#w = 20
y = '25'
try:
    print('w = ' + w)
except NameError:
    print("Variable w is not defined")
except:  # You *can* catch all errors, but probably shouldn't.
    print("Something else went wrong")
finally:
    print('y = ' + y)
#+END_SRC

** 3. More useful pandas practice
   :PROPERTIES:
   :CUSTOM_ID: more-useful-pandas-practice
   :END:

#+BEGIN_SRC ipython
import pandas as pd
import numpy as np

#sample dataset from https://ww2.amstat.org/censusatschool/
#+END_SRC

#+BEGIN_SRC ipython
#If your dataset is located in the same folder as your code, reading a CSV is straightforward:

df = pd.read_csv('Example_CAStudents.csv')
df.head()
#+END_SRC

#+BEGIN_SRC ipython
df.index
#+END_SRC

#+BEGIN_SRC ipython
df.columns
#+END_SRC

#+BEGIN_SRC ipython
#describe() shows a quick statistic summary of your data:
df.describe()
#+END_SRC

*** Quick manipulations
    :PROPERTIES:
    :CUSTOM_ID: quick-manipulations
    :END:

#+BEGIN_SRC ipython
#to transpose your data:
df.T

#to sort your data by a colum (say we wanted to sort by age, or the column 'Ageyears')
df.sort_values(by='Ageyears')
#+END_SRC

*** Selecting data
    :PROPERTIES:
    :CUSTOM_ID: selecting-data
    :END:

#+BEGIN_SRC ipython
#selecting a single column (these methods get the same result)
h_1 = df['Height_cm']
h_2 = df.Height_cm
#+END_SRC

#+BEGIN_SRC ipython
#selecting a subset of columns (note that both endpoints are included in the selection)
df.loc[:, ['Country','ClassGrade']]
#+END_SRC

#+BEGIN_SRC ipython
#selecting a subset of rows (note that the second endpoint is *not* included in the selection)
df[0:2]
#+END_SRC

#+BEGIN_SRC ipython
#getting a single value
df.at[1, 'Superpower']
#+END_SRC

#+BEGIN_SRC ipython
# Exercise: use pandas manipulations to construct a sub-dataset of the 5 tallest girls, sorted by age, 
#    and removing from the data all of the "hours" columns (ie Work_At_Home_Hours)

s = #your code here
#+END_SRC
